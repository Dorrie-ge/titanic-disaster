ğŸ›³ï¸ Titanic Survival Prediction (Python & R)
ğŸ“˜ Overview

This repository contains two complete environments â€” one in Python and one in R â€” that build and train logistic regression models to predict passenger survival from the Titanic disaster (April 15, 1912).

Both environments are fully containerized with Docker, so the grader can reproduce all results by following this README without installing any additional packages.

ğŸ“ Repository Structure
titanic-disaster/
â”œâ”€â”€ Dockerfile                 # Python Dockerfile
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ README.md                  # This instruction file
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/                   # Python container scripts
â”‚   â”‚   â””â”€â”€ main.py
â”‚   â”œâ”€â”€ r_app/                 # R container scripts
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ main.R
â”‚   â””â”€â”€ data/                  # Place data here (not included)
â””â”€â”€ .gitignore

ğŸ§© Step 1 â€” Clone the Repository

In your terminal:

git clone https://github.com/your-username/titanic-disaster.git
cd titanic-disaster


(Replace your-username with your GitHub username if needed.)

ğŸ§© Step 2 â€” Download the Data

You must manually download the Kaggle Titanic dataset (not included in this repo).

Go to:
ğŸ‘‰ https://www.kaggle.com/competitions/titanic/data

Download the following files:

train.csv

test.csv

gender_submission.csv

Place them inside:

titanic-disaster/src/data/


âœ… Your local folder should now look like:

src/data/train.csv
src/data/test.csv
src/data/gender_submission.csv

ğŸ Step 3 â€” Run the Python Docker Container
ğŸ§± Build the Docker image

From the project root folder (titanic-disaster):

docker build -t titanic-app .

â–¶ï¸ Run the container
docker run --rm -v "$PWD/src/data:/app/src/data" titanic-app

ğŸ§¾ Expected Output

The terminal should print:

[INFO] Loading datasets...
âœ… train.csv shape: (891, 12)
âœ… test.csv shape: (418, 11)

[TRAIN] Training Logistic Regression model...
[METRICS] Training Accuracy: 0.7963
[METRICS] Validation Accuracy: 0.7877
[OUTPUT] Predictions saved to src/data/predictions.csv
[DONE] Steps 15â€“18 completed successfully âœ…

ğŸ“‚ Output File
src/data/predictions.csv

ğŸ“ˆ Step 4 â€” Run the R Docker Container
ğŸ§± Build the Docker image
docker build -t titanic-r -f src/r_app/Dockerfile src/r_app

â–¶ï¸ Run the container
docker run --rm -v "$PWD/src/data:/app/src/data" titanic-r

ğŸ§¾ Expected Output

The terminal should print:

[INFO] Loading dataset...
âœ… train.csv shape: 891 rows 12 cols
[TRAIN] Model trained successfully!
[METRICS] Training Accuracy:  0.8093
[METRICS] Validation Accuracy: 0.7472
[OUTPUT] Predictions saved to src/data/predictions_R.csv
[DONE] R steps 14â€“21 completed successfully âœ…

ğŸ“‚ Output File
src/data/predictions_R.csv

ğŸ§® Step 5 â€” Model Summary
Environment	Language	Algorithm	Accuracy (Train / Validation)	Output
Python	scikit-learn	Logistic Regression	~0.79 / ~0.78	predictions.csv
R	glm (caret)	Logistic Regression	~0.81 / ~0.75	predictions_R.csv
ğŸ§° Step 6 â€” Local (Non-Docker) Run (Optional)
Run Python locally
pip install -r requirements.txt
python src/app/main.py

Run R locally
install.packages(c("tidyverse", "caret"))
source("src/r_app/main.R")

ğŸ Step 7 â€” What the Grader Should See

After running both containers, the grader should have:

src/data/predictions.csv
src/data/predictions_R.csv


Both files contain predicted survival outcomes for all passengers in test.csv.

All steps print informative progress messages to the terminal (e.g., data cleaning, model training, accuracy scores, prediction output).

ğŸ§¾ Notes

Both containers are self-contained and reproducible.

Only train.csv and test.csv are required inputs.

.gitignore ensures no datasets are uploaded to GitHub.

Each container outputs a clear [DONE] message when finished.